{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12298481,"sourceType":"datasetVersion","datasetId":7751521}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport cv2\nfrom sklearn.cluster import KMeans\n\n# ✅ Step 1: Input & Output Paths\ninput_folder = \"/kaggle/input/violence/Violence\"\noutput_base = \"/kaggle/working/Dataset_K\"\n\n# ✅ Step 2: Load and flatten images with OpenCV\nimage_data = []\nimage_paths = []\n\nfor file in os.listdir(input_folder):\n    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n        path = os.path.join(input_folder, file)\n        try:\n            img = cv2.imread(path)\n            img = cv2.resize(img, (224, 224))  # Resize for uniformity\n            img = img / 255.0  # Normalize\n            image_data.append(img.flatten())  # Flatten image\n            image_paths.append(path)\n        except:\n            continue\n\nimage_data = np.array(image_data)\n\n# ✅ Step 3: KMeans Clustering and Folder Creation\nfor k in range(2, 11):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(image_data)\n\n    k_dir = f\"{output_base}{k}\"\n    os.makedirs(k_dir, exist_ok=True)\n\n    for cluster_id in range(k):\n        os.makedirs(os.path.join(k_dir, f\"Cluster_{cluster_id}\"), exist_ok=True)\n\n    for idx, label in enumerate(labels):\n        src = image_paths[idx]\n        dst = os.path.join(k_dir, f\"Cluster_{label}\", os.path.basename(src))\n        shutil.copy(src, dst)\n\nprint(\"✅ Clustering complete. Check /kaggle/working for output folders.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T06:02:12.120901Z","iopub.execute_input":"2025-06-27T06:02:12.121236Z","iopub.status.idle":"2025-06-27T06:22:45.202861Z","shell.execute_reply.started":"2025-06-27T06:02:12.121212Z","shell.execute_reply":"2025-06-27T06:22:45.202126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom sklearn.metrics import accuracy_score\n\n# ✅ Configuration\nbase_path = \"/kaggle/working\"\nimg_size = (224, 224)\nbatch_size = 32\nepochs = 3\nk_values = list(range(2, 11))\naccuracies = []\n\n# ✅ Step-by-step over K=2 to 10\nfor k in k_values:\n    dataset_path = os.path.join(base_path, f\"Dataset_K{k}\")\n    \n    if not os.path.exists(dataset_path):\n        continue  # Skip if folder not found\n\n    # Load dataset\n    dataset = image_dataset_from_directory(\n        dataset_path,\n        image_size=img_size,\n        batch_size=batch_size,\n        label_mode='int',\n        shuffle=True,\n        seed=42,\n        validation_split=0.2,\n        subset='both'\n    )\n\n    train_ds, val_ds = dataset\n\n    # ✅ Build DenseNet201\n    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    output = Dense(k, activation='softmax')(x)  # K classes output\n\n    model = Model(inputs=base_model.input, outputs=output)\n    model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Train model\n    model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=0)\n\n    # Evaluate accuracy\n    val_labels = []\n    val_preds = []\n\n    for images, labels in val_ds:\n        preds = model.predict(images, verbose=0)\n        val_labels.extend(labels.numpy())\n        val_preds.extend(np.argmax(preds, axis=1))\n\n    acc = accuracy_score(val_labels, val_preds)\n    accuracies.append(acc)\n    print(f\"K={k}: Accuracy={acc:.4f}\")\n\n# ✅ Bar Chart\nplt.figure(figsize=(10, 6))\nbars = plt.bar(k_values, accuracies, color='skyblue', edgecolor='black')\nplt.xlabel(\"Number of Clusters (K)\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"DenseNet201 Accuracy on K-Means Clustered Datasets (K=2 to 10)\")\nplt.ylim(0.0, 1.0)\nplt.yticks(np.arange(0.0, 1.01, 0.10))\nplt.xticks(k_values)\n\n# Annotate bars\nfor bar, acc in zip(bars, accuracies):\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f\"{acc:.4f}\", ha='center', va='bottom', fontsize=10)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T06:25:55.337062Z","iopub.execute_input":"2025-06-27T06:25:55.337918Z","iopub.status.idle":"2025-06-27T06:47:51.268410Z","shell.execute_reply.started":"2025-06-27T06:25:55.337890Z","shell.execute_reply":"2025-06-27T06:47:51.267488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.savefig(\"/kaggle/working/densenet_kmeans_accuracy.png\", dpi=300)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T06:52:43.571313Z","iopub.execute_input":"2025-06-27T06:52:43.572024Z","iopub.status.idle":"2025-06-27T06:52:43.675912Z","shell.execute_reply.started":"2025-06-27T06:52:43.571999Z","shell.execute_reply":"2025-06-27T06:52:43.675237Z"}},"outputs":[],"execution_count":null}]}