{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriariit/Violence_Videos_Detection/blob/main/Violence_Detection_from_Hockey_Images_Part_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2b65RJ99bFs",
        "outputId": "886795e8-f540-44a8-e8f8-de4bb18aa232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.metrics import sensitivity_score\n",
        "from imblearn.metrics import specificity_score"
      ],
      "metadata": {
        "id": "4Qn8x-K_-lbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "dataset_path = '/content/drive/MyDrive/HDataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oob_EB2I-vpr",
        "outputId": "dfff253c-765e-4802-fe1f-6f83d43f1828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.metrics import sensitivity_score\n",
        "from imblearn.metrics import specificity_score\n",
        "import csv # Import the csv module\n",
        "\n",
        "def load_images_from_folder(folder, label):\n",
        "    \"\"\"Load images from a folder, preprocess, and assign labels.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        # Load and preprocess image\n",
        "        img = load_img(img_path, target_size=(224, 224))  # Resize image to 224x224\n",
        "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "def build_transfer_learning_model(base_model_fn, input_shape=(224, 224, 3), learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Builds a binary classification model using a specified base model function.\n",
        "\n",
        "    Parameters:\n",
        "    - base_model_fn: a function from keras.applications (e.g., VGG16, ResNet50V2)\n",
        "    - input_shape: input shape of the images\n",
        "    - learning_rate: learning rate for the optimizer\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras Model\n",
        "    \"\"\"\n",
        "    # Load the base model without the top classification layer\n",
        "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Final model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate(base_model, X_test, y_test, output_file=\"classification_metrics.csv\"):\n",
        "    # Predict probabilities\n",
        "\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        writer.writerow([\"Accuracy\", \"Cohen-Kappa\", \"Precision\", \"Recall\", \"F1-Score\", \"AUROC\", \"MCC\", \"Specificity\", \"G-Mean\", \"Type I Error\",\"Type II Error\"])\n",
        "\n",
        "        y_probs = base_model.predict(X_test)\n",
        "        y_pred = (y_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "        # Classification Report (includes precision, recall, F1-score)\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "        # Individual Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        auroc = roc_auc_score(y_test, y_probs, average='weighted')\n",
        "        mcc = matthews_corrcoef(y_test, y_pred)\n",
        "        specificity = specificity_score(y_test, y_pred, average='weighted')\n",
        "        g_mean = geometric_mean_score(y_test, y_pred, average='weighted')\n",
        "        type_i_error = 1 - g_mean\n",
        "        type_ii_error = 1 - specificity\n",
        "\n",
        "\n",
        "        writer.writerow([accuracy, cohen_kappa, precision, recall, f1, auroc, mcc, specificity, g_mean, type_i_error, type_ii_error])\n",
        "\n",
        "        # Display results\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Cohen's Kappa:\", cohen_kappa)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1-Score:\", f1)\n",
        "        print(\"AUROC:\", auroc)\n",
        "        print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
        "        print(\"Specificity\",specificity)\n",
        "        print(\"Geometric Mean\",g_mean)\n",
        "        print(\"Type I Error\",type_i_error)\n",
        "        print(\"Type II Error\",type_ii_error)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jsdzM7Kl4IyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the frames\n",
        "nonviolence_folder = '/content/drive/MyDrive/HDataset/Nofight'\n",
        "violence_folder = '/content/drive/MyDrive/HDataset/Fight'"
      ],
      "metadata": {
        "id": "UDo6thHZ_qd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images and labels for each class\n",
        "violence_images, violence_labels = load_images_from_folder(violence_folder, 1)  # Label 1 for Violence\n",
        "nonviolence_images, nonviolence_labels = load_images_from_folder(nonviolence_folder, 0)  # Label 0 for Non-Violence\n",
        "\n",
        "# Combine the datasets\n",
        "X = np.concatenate((violence_images, nonviolence_images), axis=0)\n",
        "y = np.concatenate((violence_labels, nonviolence_labels), axis=0)\n",
        "\n",
        "# Shuffle the dataset\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "print(f\"Dataset loaded and shuffled.\")\n",
        "print(f\"Total samples: {len(y)}\")\n",
        "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377RzlxDAARi",
        "outputId": "f1be20c3-7043-49f0-e4bd-7ef2f2e5f44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and shuffled.\n",
            "Total samples: 2000\n",
            "Shape of X: (2000, 224, 224, 3), Shape of y: (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testin\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oPsESuudAh_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_densenet201 = build_transfer_learning_model(DenseNet201)\n",
        "model_densenet201.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_densenet201 = model_densenet201.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_densenet201}\")\n",
        "evaluate(model_densenet201, X_test, y_test,\"densenet201_classification.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnJoOtW3Jomx",
        "outputId": "ac1fdd51-b36c-45b7-d265-c46b64a5370e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.7277 - loss: 0.9319 - val_accuracy: 0.9075 - val_loss: 0.2709\n",
            "Epoch 2/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 142ms/step - accuracy: 0.9178 - loss: 0.2082 - val_accuracy: 0.9250 - val_loss: 0.2122\n",
            "Epoch 3/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 142ms/step - accuracy: 0.9664 - loss: 0.1064 - val_accuracy: 0.9225 - val_loss: 0.2115\n",
            "Epoch 4/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.9333 - loss: 0.1521 - val_accuracy: 0.9350 - val_loss: 0.1859\n",
            "Epoch 5/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 0.9642 - loss: 0.0975 - val_accuracy: 0.9325 - val_loss: 0.1756\n",
            "Epoch 6/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 0.9795 - loss: 0.0694 - val_accuracy: 0.9350 - val_loss: 0.1865\n",
            "Accuracy: 0.9350000023841858\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.94       203\n",
            "           1       0.92      0.95      0.94       197\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.94      0.94      0.94       400\n",
            "weighted avg       0.94      0.94      0.94       400\n",
            "\n",
            "Accuracy: 0.935\n",
            "Cohen's Kappa: 0.8700292434202305\n",
            "Precision: 0.9354208446900552\n",
            "Recall: 0.935\n",
            "F1-Score: 0.935\n",
            "AUROC: 0.9840464104423495\n",
            "Matthews Correlation Coefficient (MCC): 0.8704208446900553\n",
            "Specificity 0.9354208446900552\n",
            "Geometric Mean 0.9352103986725135\n",
            "Type I Error 0.06478960132748646\n",
            "Type II Error 0.06457915530994485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inceptionv3 = build_transfer_learning_model(InceptionV3)\n",
        "model_inceptionv3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_inceptionv3 = model_inceptionv3.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_inceptionv3}\")\n",
        "evaluate(model_inceptionv3, X_test, y_test,\"inceptionv3_classification.csv\")"
      ],
      "metadata": {
        "id": "Mp56g4TlKTyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9f4c60-181a-4c73-c787-05636e787f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 371ms/step - accuracy: 0.7228 - loss: 0.9681 - val_accuracy: 0.9100 - val_loss: 0.2305\n",
            "Epoch 2/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.9165 - loss: 0.2413 - val_accuracy: 0.9250 - val_loss: 0.2098\n",
            "Epoch 3/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.9497 - loss: 0.1612 - val_accuracy: 0.9150 - val_loss: 0.2187\n",
            "Epoch 4/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.9611 - loss: 0.1283 - val_accuracy: 0.9350 - val_loss: 0.1728\n",
            "Epoch 5/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9601 - loss: 0.1290 - val_accuracy: 0.9325 - val_loss: 0.1810\n",
            "Epoch 6/6\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.9358 - loss: 0.1530 - val_accuracy: 0.9350 - val_loss: 0.1949\n",
            "Accuracy: 0.9350000023841858\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 552ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93       203\n",
            "           1       0.91      0.97      0.94       197\n",
            "\n",
            "    accuracy                           0.94       400\n",
            "   macro avg       0.94      0.94      0.93       400\n",
            "weighted avg       0.94      0.94      0.93       400\n",
            "\n",
            "Accuracy: 0.935\n",
            "Cohen's Kappa: 0.8701071615916869\n",
            "Precision: 0.9372064244339126\n",
            "Recall: 0.935\n",
            "F1-Score: 0.934954481792717\n",
            "AUROC: 0.9821209772198746\n",
            "Matthews Correlation Coefficient (MCC): 0.8722432514737605\n",
            "Specificity 0.9360209797204371\n",
            "Geometric Mean 0.9355103505780193\n",
            "Type I Error 0.06448964942198065\n",
            "Type II Error 0.06397902027956293\n"
          ]
        }
      ]
    }
  ]
}