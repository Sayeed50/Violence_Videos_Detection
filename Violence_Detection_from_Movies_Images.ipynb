{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriariit/Violence_Videos_Detection/blob/main/Violence_Detection_from_Movies_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2b65RJ99bFs",
        "outputId": "5a269f05-9dae-4a50-ef40-0ee578002869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qn8x-K_-lbX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import csv\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.metrics import sensitivity_score\n",
        "from imblearn.metrics import specificity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oob_EB2I-vpr",
        "outputId": "9afe0c3e-6022-4d86-ee0e-42e10b63f8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "dataset_path = '/content/drive/MyDrive/MDataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJKsoLjW--Cm"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder, label):\n",
        "    \"\"\"Load images from a folder, preprocess, and assign labels.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        # Load and preprocess image\n",
        "        img = load_img(img_path, target_size=(224, 224))  # Resize image to 224x224\n",
        "        img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "def build_transfer_learning_model(base_model_fn, input_shape=(224, 224, 3), learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Builds a binary classification model using a specified base model function.\n",
        "\n",
        "    Parameters:\n",
        "    - base_model_fn: a function from keras.applications (e.g., VGG16, ResNet50V2)\n",
        "    - input_shape: input shape of the images\n",
        "    - learning_rate: learning rate for the optimizer\n",
        "\n",
        "    Returns:\n",
        "    - Compiled Keras Model\n",
        "    \"\"\"\n",
        "    # Load the base model without the top classification layer\n",
        "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Final model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate(base_model, X_test, y_test, output_file=\"classification_metrics.csv\"):\n",
        "    # Predict probabilities\n",
        "\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        writer.writerow([\"Accuracy\", \"Cohen-Kappa\", \"Precision\", \"Recall\", \"F1-Score\", \"AUROC\", \"MCC\", \"Specificity\", \"G-Mean\", \"Type I Error\",\"Type II Error\"])\n",
        "\n",
        "        y_probs = base_model.predict(X_test)\n",
        "        y_pred = (y_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "        # Classification Report (includes precision, recall, F1-score)\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "        # Individual Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        auroc = roc_auc_score(y_test, y_probs, average='weighted')\n",
        "        mcc = matthews_corrcoef(y_test, y_pred)\n",
        "        specificity = specificity_score(y_test, y_pred, average='weighted')\n",
        "        g_mean = geometric_mean_score(y_test, y_pred, average='weighted')\n",
        "        type_i_error = 1 - g_mean\n",
        "        type_ii_error = 1 - specificity\n",
        "\n",
        "\n",
        "        writer.writerow([accuracy, cohen_kappa, precision, recall, f1, auroc, mcc, specificity, g_mean, type_i_error, type_ii_error])\n",
        "\n",
        "        # Display results\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"Cohen's Kappa:\", cohen_kappa)\n",
        "        print(\"Precision:\", precision)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"F1-Score:\", f1)\n",
        "        print(\"AUROC:\", auroc)\n",
        "        print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n",
        "        print(\"Specificity\",specificity)\n",
        "        print(\"Geometric Mean\",g_mean)\n",
        "        print(\"Type I Error\",type_i_error)\n",
        "        print(\"Type II Error\",type_ii_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDo6thHZ_qd4"
      },
      "outputs": [],
      "source": [
        "# Paths to the frames\n",
        "nonviolence_folder = '/content/drive/MyDrive/MDataset/noFights'\n",
        "violence_folder = '/content/drive/MyDrive/MDataset/fights'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377RzlxDAARi",
        "outputId": "14a0a1c0-5f7e-4cc7-fc89-3735d66cef51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and shuffled.\n",
            "Total samples: 428\n",
            "Shape of X: (428, 224, 224, 3), Shape of y: (428,)\n"
          ]
        }
      ],
      "source": [
        "# Load images and labels for each class\n",
        "violence_images, violence_labels = load_images_from_folder(violence_folder, 1)  # Label 1 for Violence\n",
        "nonviolence_images, nonviolence_labels = load_images_from_folder(nonviolence_folder, 0)  # Label 0 for Non-Violence\n",
        "\n",
        "# Combine the datasets\n",
        "X = np.concatenate((violence_images, nonviolence_images), axis=0)\n",
        "y = np.concatenate((violence_labels, nonviolence_labels), axis=0)\n",
        "\n",
        "# Shuffle the dataset\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "print(f\"Dataset loaded and shuffled.\")\n",
        "print(f\"Total samples: {len(y)}\")\n",
        "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPsESuudAh_w"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and testin\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_lu8hocAWZ0",
        "outputId": "85cba8f2-7353-4661-f72d-7ea75308a259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 672ms/step - accuracy: 0.6843 - loss: 0.5637 - val_accuracy: 0.9651 - val_loss: 0.2612\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 0.9230 - loss: 0.2538 - val_accuracy: 0.9186 - val_loss: 0.1788\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.9431 - loss: 0.1577 - val_accuracy: 0.9884 - val_loss: 0.0978\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - accuracy: 0.9717 - loss: 0.1086 - val_accuracy: 0.9884 - val_loss: 0.0719\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.9814 - loss: 0.0791 - val_accuracy: 0.9884 - val_loss: 0.0606\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.9885 - loss: 0.0526 - val_accuracy: 0.9884 - val_loss: 0.0452\n",
            "Accuracy: 0.9883720874786377\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 404ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        35\n",
            "           1       0.98      1.00      0.99        51\n",
            "\n",
            "    accuracy                           0.99        86\n",
            "   macro avg       0.99      0.99      0.99        86\n",
            "weighted avg       0.99      0.99      0.99        86\n",
            "\n",
            "Accuracy: 0.9883720930232558\n",
            "Cohen's Kappa: 0.975801913337085\n",
            "Precision: 0.9885957066189625\n",
            "Recall: 0.9883720930232558\n",
            "F1-Score: 0.9883442789781446\n",
            "AUROC: 1.0\n",
            "Matthews Correlation Coefficient (MCC): 0.9760877279974647\n",
            "Specificity 0.9830564784053156\n",
            "Geometric Mean 0.9857107025499585\n",
            "Type I Error 0.014289297450041483\n",
            "Type II Error 0.016943521594684374\n"
          ]
        }
      ],
      "source": [
        "model_vgg16 = build_transfer_learning_model(VGG16)\n",
        "model_vgg16.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_vgg16 = model_vgg16.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_vgg16}\")\n",
        "evaluate(model_vgg16, X_test, y_test,\"vgg16_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw-s3lVcAzmj",
        "outputId": "77f96990-a018-4f07-d99f-e703b98b732a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 625ms/step - accuracy: 0.6300 - loss: 0.6084 - val_accuracy: 0.8721 - val_loss: 0.3691\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 258ms/step - accuracy: 0.9023 - loss: 0.3163 - val_accuracy: 0.9070 - val_loss: 0.2002\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - accuracy: 0.9357 - loss: 0.2114 - val_accuracy: 0.9186 - val_loss: 0.1649\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - accuracy: 0.9270 - loss: 0.1834 - val_accuracy: 0.9884 - val_loss: 0.1132\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 261ms/step - accuracy: 0.9383 - loss: 0.1486 - val_accuracy: 1.0000 - val_loss: 0.0885\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.9824 - loss: 0.1091 - val_accuracy: 1.0000 - val_loss: 0.0613\n",
            "Accuracy: 1.0\n",
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 190ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 31 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79e049d5c220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 485ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        51\n",
            "\n",
            "    accuracy                           1.00        86\n",
            "   macro avg       1.00      1.00      1.00        86\n",
            "weighted avg       1.00      1.00      1.00        86\n",
            "\n",
            "Accuracy: 1.0\n",
            "Cohen's Kappa: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "AUROC: 1.0\n",
            "Matthews Correlation Coefficient (MCC): 1.0\n",
            "Specificity 1.0\n",
            "Geometric Mean 1.0\n",
            "Type I Error 0.0\n",
            "Type II Error 0.0\n"
          ]
        }
      ],
      "source": [
        "model_vgg19 = build_transfer_learning_model(VGG19)\n",
        "model_vgg19.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_vgg19 = model_vgg19.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_vgg19}\")\n",
        "evaluate(model_vgg19, X_test, y_test,\"vgg19_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr89iSHlA702",
        "outputId": "eed97102-7c77-4ff4-c346-5b5f8dc5593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.5278 - loss: 0.7011 - val_accuracy: 0.4070 - val_loss: 0.5934\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.7335 - loss: 0.4801 - val_accuracy: 0.9884 - val_loss: 0.3092\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9063 - loss: 0.3418 - val_accuracy: 0.9419 - val_loss: 0.2143\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9615 - loss: 0.2422 - val_accuracy: 0.9884 - val_loss: 0.1645\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9617 - loss: 0.1956 - val_accuracy: 0.9884 - val_loss: 0.1328\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9590 - loss: 0.1694 - val_accuracy: 0.9884 - val_loss: 0.1151\n",
            "Accuracy: 0.9883720874786377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 32 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79e04b469620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        35\n",
            "           1       0.98      1.00      0.99        51\n",
            "\n",
            "    accuracy                           0.99        86\n",
            "   macro avg       0.99      0.99      0.99        86\n",
            "weighted avg       0.99      0.99      0.99        86\n",
            "\n",
            "Accuracy: 0.9883720930232558\n",
            "Cohen's Kappa: 0.975801913337085\n",
            "Precision: 0.9885957066189625\n",
            "Recall: 0.9883720930232558\n",
            "F1-Score: 0.9883442789781446\n",
            "AUROC: 0.9988795518207283\n",
            "Matthews Correlation Coefficient (MCC): 0.9760877279974647\n",
            "Specificity 0.9830564784053156\n",
            "Geometric Mean 0.9857107025499585\n",
            "Type I Error 0.014289297450041483\n",
            "Type II Error 0.016943521594684374\n"
          ]
        }
      ],
      "source": [
        "model_mobilenetv3 = build_transfer_learning_model(MobileNetV3Large)\n",
        "model_mobilenetv3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_mobilenetv3 = model_mobilenetv3.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_mobilenetv3}\")\n",
        "evaluate(model_mobilenetv3, X_test, y_test,\"mobilenetv3_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq2Ck08iBBZ5",
        "outputId": "9cfca026-1af2-4d5b-ab79-fb7226ad871a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1s/step - accuracy: 0.7591 - loss: 0.6497 - val_accuracy: 0.9535 - val_loss: 0.1742\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.9627 - loss: 0.0819 - val_accuracy: 0.9767 - val_loss: 0.0297\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9919 - loss: 0.0160 - val_accuracy: 0.9884 - val_loss: 0.0340\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9945 - loss: 0.0077 - val_accuracy: 0.9884 - val_loss: 0.0249\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9884 - val_loss: 0.0244\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 5.2552e-04 - val_accuracy: 0.9884 - val_loss: 0.0228\n",
            "Accuracy: 0.9883720874786377\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        35\n",
            "           1       1.00      0.98      0.99        51\n",
            "\n",
            "    accuracy                           0.99        86\n",
            "   macro avg       0.99      0.99      0.99        86\n",
            "weighted avg       0.99      0.99      0.99        86\n",
            "\n",
            "Accuracy: 0.9883720930232558\n",
            "Cohen's Kappa: 0.9760178471834914\n",
            "Precision: 0.9886950904392764\n",
            "Recall: 0.9883720930232558\n",
            "F1-Score: 0.9883964157961816\n",
            "AUROC: 1.0\n",
            "Matthews Correlation Coefficient (MCC): 0.9762986435483435\n",
            "Specificity 0.9920200638394893\n",
            "Geometric Mean 0.9901943984986482\n",
            "Type I Error 0.00980560150135179\n",
            "Type II Error 0.007979936160510737\n"
          ]
        }
      ],
      "source": [
        "model_resnet50v2 = build_transfer_learning_model(ResNet50V2)\n",
        "model_resnet50v2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_resnet50v2 = model_resnet50v2.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_resnet50v2}\")\n",
        "evaluate(model_resnet50v2, X_test, y_test,\"resnet50v2_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "httJBCt1Gq4w",
        "outputId": "dfddb75f-5431-4594-8298-5d984de9ec27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 4s/step - accuracy: 0.7338 - loss: 0.7990 - val_accuracy: 0.8605 - val_loss: 0.2756\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 191ms/step - accuracy: 0.8812 - loss: 0.2500 - val_accuracy: 0.9186 - val_loss: 0.1277\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.9770 - loss: 0.0717 - val_accuracy: 0.9535 - val_loss: 0.0691\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.9895 - loss: 0.0308 - val_accuracy: 0.9767 - val_loss: 0.0510\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.9869 - loss: 0.0364 - val_accuracy: 0.9884 - val_loss: 0.0345\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.9924 - loss: 0.0181 - val_accuracy: 0.9884 - val_loss: 0.0369\n",
            "Accuracy: 0.9883720874786377\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        35\n",
            "           1       1.00      0.98      0.99        51\n",
            "\n",
            "    accuracy                           0.99        86\n",
            "   macro avg       0.99      0.99      0.99        86\n",
            "weighted avg       0.99      0.99      0.99        86\n",
            "\n",
            "Accuracy: 0.9883720930232558\n",
            "Cohen's Kappa: 0.9760178471834914\n",
            "Precision: 0.9886950904392764\n",
            "Recall: 0.9883720930232558\n",
            "F1-Score: 0.9883964157961816\n",
            "AUROC: 0.9994397759103641\n",
            "Matthews Correlation Coefficient (MCC): 0.9762986435483435\n",
            "Specificity 0.9920200638394893\n",
            "Geometric Mean 0.9901943984986482\n",
            "Type I Error 0.00980560150135179\n",
            "Type II Error 0.007979936160510737\n"
          ]
        }
      ],
      "source": [
        "model_inceptionresnetv2 = build_transfer_learning_model(InceptionResNetV2)\n",
        "model_inceptionresnetv2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_inceptionresnetv2 = model_inceptionresnetv2.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_inceptionresnetv2}\")\n",
        "evaluate(model_inceptionresnetv2, X_test, y_test,\"inceptionresnetv2_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPi_A468H-W-",
        "outputId": "dcd956db-8726-4a0f-f4be-e41a0f83be3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 3s/step - accuracy: 0.7887 - loss: 0.4573 - val_accuracy: 0.9767 - val_loss: 0.1077\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 104ms/step - accuracy: 0.9280 - loss: 0.1437 - val_accuracy: 0.9884 - val_loss: 0.0509\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.9900 - loss: 0.0490 - val_accuracy: 0.9651 - val_loss: 0.0663\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9808 - loss: 0.0489 - val_accuracy: 0.9884 - val_loss: 0.0560\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9918 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0249\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9917 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
            "Accuracy: 1.0\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        51\n",
            "\n",
            "    accuracy                           1.00        86\n",
            "   macro avg       1.00      1.00      1.00        86\n",
            "weighted avg       1.00      1.00      1.00        86\n",
            "\n",
            "Accuracy: 1.0\n",
            "Cohen's Kappa: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "AUROC: 1.0\n",
            "Matthews Correlation Coefficient (MCC): 1.0\n",
            "Specificity 1.0\n",
            "Geometric Mean 1.0\n",
            "Type I Error 0.0\n",
            "Type II Error 0.0\n"
          ]
        }
      ],
      "source": [
        "model_densenet121 = build_transfer_learning_model(DenseNet121)\n",
        "model_densenet121.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_densenet121 = model_densenet121.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_densenet121}\")\n",
        "evaluate(model_densenet121, X_test, y_test,\"densenet121_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1MO53I2I1bM",
        "outputId": "ed182227-aff3-418e-a9fb-da5251b06276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.8170 - loss: 0.3522 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
            "Epoch 2/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 123ms/step - accuracy: 0.9905 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
            "Epoch 3/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9884 - val_loss: 0.0203\n",
            "Epoch 4/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
            "Epoch 5/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
            "Epoch 6/6\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
            "Accuracy: 1.0\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9s/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        51\n",
            "\n",
            "    accuracy                           1.00        86\n",
            "   macro avg       1.00      1.00      1.00        86\n",
            "weighted avg       1.00      1.00      1.00        86\n",
            "\n",
            "Accuracy: 1.0\n",
            "Cohen's Kappa: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "AUROC: 1.0\n",
            "Matthews Correlation Coefficient (MCC): 1.0\n",
            "Specificity 1.0\n",
            "Geometric Mean 1.0\n",
            "Type I Error 0.0\n",
            "Type II Error 0.0\n"
          ]
        }
      ],
      "source": [
        "model_densenet169 = build_transfer_learning_model(DenseNet169)\n",
        "model_densenet169.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_densenet169 = model_densenet169.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_densenet169}\")\n",
        "evaluate(model_densenet169, X_test, y_test,\"densenet169_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnJoOtW3Jomx",
        "outputId": "b18d88f6-a5c3-47ea-c2f9-a51e1caa8ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        }
      ],
      "source": [
        "model_densenet201 = build_transfer_learning_model(DenseNet201)\n",
        "model_densenet201.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_densenet201 = model_densenet201.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_densenet201}\")\n",
        "evaluate(model_densenet201, X_test, y_test,\"densenet201_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp56g4TlKTyn"
      },
      "outputs": [],
      "source": [
        "model_inceptionv3 = build_transfer_learning_model(InceptionV3)\n",
        "model_inceptionv3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=6, batch_size=32)\n",
        "accuracy_inceptionv3 = model_inceptionv3.evaluate(X_test, y_test, verbose=0)[1]\n",
        "print(f\"Accuracy: {accuracy_inceptionv3}\")\n",
        "evaluate(model_inceptionv3, X_test, y_test,\"inceptionv3_classification.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}